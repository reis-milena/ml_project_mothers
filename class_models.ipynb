{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Model for Working mothers after pregnancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters Tuning with GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV  #cv=cross validation\n",
    "from sklearn.tree            import DecisionTreeClassifier\n",
    "from sklearn.ensemble        import RandomForestClassifier\n",
    "from sklearn.neighbors       import KNeighborsClassifier\n",
    "from sklearn.linear_model    import LogisticRegression\n",
    "from sklearn.svm             import SVC\n",
    "from sklearn.neural_network  import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_mothers.pkl', mode = 'rb') as f:\n",
    "    X_data_training, Y_data_training, X_data_predict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((979, 6), (979,), (264, 6))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data_training.shape, Y_data_training.shape, X_data_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1.]), array([388, 591], dtype=int64))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Y_data_training, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'criterion': ['gini','entropy'],\n",
    "              'splitter': ['best','random'],\n",
    "              'min_samples_split': [2,5,10],\n",
    "              'min_samples_leaf' : [1,5,10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator = DecisionTreeClassifier(),\n",
    "                           param_grid = parameters) #it will test all combinations of parameters\n",
    "grid_search.fit(X_data_training, Y_data_training)\n",
    "best_parameters = grid_search.best_params_\n",
    "best_result = grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "0.6710779696493983\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(best_parameters) , print(best_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'criterion': ['gini','entropy'],\n",
    "              'n_estimators': [10,40,100,150],\n",
    "              'min_samples_split': [2,5,10],\n",
    "              'min_samples_leaf' : [1,5,10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator = RandomForestClassifier(),\n",
    "                           param_grid = parameters) #it will test all combinations of parameters\n",
    "grid_search.fit(X_data_training, Y_data_training)\n",
    "best_parameters = grid_search.best_params_\n",
    "best_result = grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "0.6731344845630559\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(best_parameters) , print(best_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'n_neighbors': [3,5,10,20],\n",
    "              'p': [1,2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator = KNeighborsClassifier(),\n",
    "                           param_grid = parameters) #it will test all combinations of parameters\n",
    "grid_search.fit(X_data_training, Y_data_training)\n",
    "best_parameters = grid_search.best_params_\n",
    "best_result = grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 20, 'p': 1}\n",
      "0.678226059654631\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(best_parameters) , print(best_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'tol': [0.0001,0.00001,0.000001],\n",
    "              'C': [1.0,1.5,2.0],\n",
    "              'solver' :['lbfgs','sag','saga']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator = LogisticRegression(),\n",
    "                           param_grid = parameters) #it will test all combinations of parameters\n",
    "grid_search.fit(X_data_training,Y_data_training)\n",
    "best_parameters = grid_search.best_params_\n",
    "best_result = grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1.0, 'solver': 'lbfgs', 'tol': 0.0001}\n",
      "0.6730978545264259\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(best_parameters) , print(best_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'tol': [0.001,0.0001,0.00001],\n",
    "              'C': [1.0,1.5,2.0],\n",
    "              'kernel' :['rbf','linear','poly','sigmoid']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator = SVC(),\n",
    "                           param_grid = parameters) #it will test all combinations of parameters\n",
    "grid_search.fit(X_data_training,Y_data_training)\n",
    "best_parameters = grid_search.best_params_\n",
    "best_result = grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 2.0, 'kernel': 'rbf', 'tol': 0.001}\n",
      "0.675149136577708\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(best_parameters) , print(best_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'activation': ['relu','logistic','tanh'],\n",
    "              'solver': ['adam','sgd'],\n",
    "              'batch_size' :[10,56]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ville\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ville\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ville\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ville\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ville\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ville\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ville\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ville\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ville\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ville\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(estimator = MLPClassifier(),\n",
    "                           param_grid = parameters) #it will test all combinations of parameters\n",
    "grid_search.fit(X_data_training, Y_data_training)\n",
    "best_parameters = grid_search.best_params_\n",
    "best_result = grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'tanh', 'batch_size': 10, 'solver': 'adam'}\n",
      "0.6741287284144428\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(best_parameters) , print(best_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "dec_tree_results   = []\n",
    "random_f_results   = []\n",
    "knn_results        = []\n",
    "logistic_results   = []\n",
    "svm_results        = []\n",
    "neural_net_results = []\n",
    "\n",
    "for i in range(30): #30 is very common\n",
    "    print(i)\n",
    "    kfold = KFold(n_splits = 10, shuffle = True, random_state = i)\n",
    "    #results found on Tuning with GridSearch\n",
    "    #{'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 5, 'splitter': 'random'}\n",
    "    tree_decision = DecisionTreeClassifier(criterion='gini',\n",
    "                                           min_samples_leaf=5,\n",
    "                                           min_samples_split=5,\n",
    "                                           splitter='random')\n",
    "    score = cross_val_score(tree_decision,X_data_training,Y_data_training, cv=kfold)\n",
    "    dec_tree_results.append(score.mean())\n",
    "    ##################################################################################\n",
    "    #{'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 10}\n",
    "    random_f = RandomForestClassifier(criterion='entropy',\n",
    "                                      min_samples_leaf=5,\n",
    "                                      min_samples_split=2,\n",
    "                                      n_estimators=10)\n",
    "    score = cross_val_score(random_f,X_data_training,Y_data_training, cv=kfold)\n",
    "    random_f_results.append(score.mean())\n",
    "    ##################################################################################\n",
    "    #{'n_neighbors': 20, 'p': 1}\n",
    "    knn = KNeighborsClassifier(n_neighbors=20,\n",
    "                               p = 1)\n",
    "    score = cross_val_score(knn,X_data_training,Y_data_training, cv=kfold)\n",
    "    knn_results.append(score.mean())\n",
    "    ##################################################################################\n",
    "    #{'C': 1.0, 'solver': 'lbfgs', 'tol': 0.0001}\n",
    "    logistic = LogisticRegression(C=1.0,\n",
    "                                  solver ='lbfgs',\n",
    "                                  tol = 0.0001)\n",
    "    score = cross_val_score(logistic,X_data_training,Y_data_training, cv=kfold)\n",
    "    logistic_results.append(score.mean())\n",
    "    ##################################################################################\n",
    "    #{'C': 2.0, 'kernel': 'rbf', 'tol': 0.001}\n",
    "    svm = SVC(C =2.0,\n",
    "              kernel = 'rbf',\n",
    "              tol = 0.001)\n",
    "    score = cross_val_score(svm,X_data_training,Y_data_training, cv=kfold)\n",
    "    svm_results.append(score.mean())\n",
    "    ##################################################################################\n",
    "    #{'activation': 'tanh', 'batch_size': 10, 'solver': 'adam'}\n",
    "    neura_network = MLPClassifier(activation='tanh',\n",
    "                                  batch_size= 10,\n",
    "                                  solver= 'adam')\n",
    "    score = cross_val_score(neura_network,X_data_training,Y_data_training, cv=kfold)\n",
    "    neural_net_results.append(score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>KNN</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Neural Network</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.656775</td>\n",
       "      <td>0.680297</td>\n",
       "      <td>0.666021</td>\n",
       "      <td>0.662887</td>\n",
       "      <td>0.661887</td>\n",
       "      <td>0.663928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.632369</td>\n",
       "      <td>0.647633</td>\n",
       "      <td>0.655817</td>\n",
       "      <td>0.662950</td>\n",
       "      <td>0.639470</td>\n",
       "      <td>0.672144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.646560</td>\n",
       "      <td>0.654702</td>\n",
       "      <td>0.668010</td>\n",
       "      <td>0.665906</td>\n",
       "      <td>0.652640</td>\n",
       "      <td>0.664885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.652609</td>\n",
       "      <td>0.648548</td>\n",
       "      <td>0.658763</td>\n",
       "      <td>0.667926</td>\n",
       "      <td>0.647517</td>\n",
       "      <td>0.666895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.643551</td>\n",
       "      <td>0.659888</td>\n",
       "      <td>0.661940</td>\n",
       "      <td>0.669072</td>\n",
       "      <td>0.655849</td>\n",
       "      <td>0.666011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.646550</td>\n",
       "      <td>0.655796</td>\n",
       "      <td>0.666979</td>\n",
       "      <td>0.677183</td>\n",
       "      <td>0.648601</td>\n",
       "      <td>0.674111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.654713</td>\n",
       "      <td>0.663865</td>\n",
       "      <td>0.658784</td>\n",
       "      <td>0.675142</td>\n",
       "      <td>0.662908</td>\n",
       "      <td>0.671060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.652661</td>\n",
       "      <td>0.658815</td>\n",
       "      <td>0.673101</td>\n",
       "      <td>0.671102</td>\n",
       "      <td>0.651641</td>\n",
       "      <td>0.668010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.657753</td>\n",
       "      <td>0.664917</td>\n",
       "      <td>0.673070</td>\n",
       "      <td>0.669051</td>\n",
       "      <td>0.672123</td>\n",
       "      <td>0.669051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.649684</td>\n",
       "      <td>0.652756</td>\n",
       "      <td>0.657816</td>\n",
       "      <td>0.666011</td>\n",
       "      <td>0.641542</td>\n",
       "      <td>0.673185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.654734</td>\n",
       "      <td>0.661919</td>\n",
       "      <td>0.669072</td>\n",
       "      <td>0.660888</td>\n",
       "      <td>0.658794</td>\n",
       "      <td>0.672133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.642468</td>\n",
       "      <td>0.640385</td>\n",
       "      <td>0.667000</td>\n",
       "      <td>0.672112</td>\n",
       "      <td>0.658826</td>\n",
       "      <td>0.671071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.651683</td>\n",
       "      <td>0.643520</td>\n",
       "      <td>0.657764</td>\n",
       "      <td>0.671050</td>\n",
       "      <td>0.666958</td>\n",
       "      <td>0.671050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.656827</td>\n",
       "      <td>0.649642</td>\n",
       "      <td>0.669104</td>\n",
       "      <td>0.674195</td>\n",
       "      <td>0.653745</td>\n",
       "      <td>0.669093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.645624</td>\n",
       "      <td>0.649705</td>\n",
       "      <td>0.663970</td>\n",
       "      <td>0.660888</td>\n",
       "      <td>0.638428</td>\n",
       "      <td>0.657785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.651736</td>\n",
       "      <td>0.661929</td>\n",
       "      <td>0.664948</td>\n",
       "      <td>0.661908</td>\n",
       "      <td>0.657837</td>\n",
       "      <td>0.663981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.658868</td>\n",
       "      <td>0.647633</td>\n",
       "      <td>0.658900</td>\n",
       "      <td>0.672165</td>\n",
       "      <td>0.659899</td>\n",
       "      <td>0.666979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.646518</td>\n",
       "      <td>0.662866</td>\n",
       "      <td>0.675131</td>\n",
       "      <td>0.664938</td>\n",
       "      <td>0.659804</td>\n",
       "      <td>0.674111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.663886</td>\n",
       "      <td>0.665948</td>\n",
       "      <td>0.675131</td>\n",
       "      <td>0.675110</td>\n",
       "      <td>0.656733</td>\n",
       "      <td>0.662866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.654650</td>\n",
       "      <td>0.651610</td>\n",
       "      <td>0.666926</td>\n",
       "      <td>0.663865</td>\n",
       "      <td>0.652640</td>\n",
       "      <td>0.666937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.644456</td>\n",
       "      <td>0.656722</td>\n",
       "      <td>0.670987</td>\n",
       "      <td>0.663823</td>\n",
       "      <td>0.659762</td>\n",
       "      <td>0.666895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.654818</td>\n",
       "      <td>0.652777</td>\n",
       "      <td>0.662981</td>\n",
       "      <td>0.659952</td>\n",
       "      <td>0.654850</td>\n",
       "      <td>0.660961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.665927</td>\n",
       "      <td>0.660804</td>\n",
       "      <td>0.667957</td>\n",
       "      <td>0.674111</td>\n",
       "      <td>0.662855</td>\n",
       "      <td>0.672060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.655712</td>\n",
       "      <td>0.652661</td>\n",
       "      <td>0.663939</td>\n",
       "      <td>0.669051</td>\n",
       "      <td>0.656775</td>\n",
       "      <td>0.668031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.652714</td>\n",
       "      <td>0.652704</td>\n",
       "      <td>0.659825</td>\n",
       "      <td>0.665001</td>\n",
       "      <td>0.663939</td>\n",
       "      <td>0.671060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.659878</td>\n",
       "      <td>0.652756</td>\n",
       "      <td>0.666021</td>\n",
       "      <td>0.674195</td>\n",
       "      <td>0.660919</td>\n",
       "      <td>0.674206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.648664</td>\n",
       "      <td>0.659878</td>\n",
       "      <td>0.662971</td>\n",
       "      <td>0.668073</td>\n",
       "      <td>0.652756</td>\n",
       "      <td>0.674206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.659836</td>\n",
       "      <td>0.661898</td>\n",
       "      <td>0.669020</td>\n",
       "      <td>0.669009</td>\n",
       "      <td>0.660867</td>\n",
       "      <td>0.665979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.645582</td>\n",
       "      <td>0.654776</td>\n",
       "      <td>0.660877</td>\n",
       "      <td>0.666021</td>\n",
       "      <td>0.644551</td>\n",
       "      <td>0.670093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.648548</td>\n",
       "      <td>0.653671</td>\n",
       "      <td>0.665916</td>\n",
       "      <td>0.665895</td>\n",
       "      <td>0.652630</td>\n",
       "      <td>0.656701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Decision Tree  Random Forest       KNN  Logistic Regression       SVM  \\\n",
       "0        0.656775       0.680297  0.666021             0.662887  0.661887   \n",
       "1        0.632369       0.647633  0.655817             0.662950  0.639470   \n",
       "2        0.646560       0.654702  0.668010             0.665906  0.652640   \n",
       "3        0.652609       0.648548  0.658763             0.667926  0.647517   \n",
       "4        0.643551       0.659888  0.661940             0.669072  0.655849   \n",
       "5        0.646550       0.655796  0.666979             0.677183  0.648601   \n",
       "6        0.654713       0.663865  0.658784             0.675142  0.662908   \n",
       "7        0.652661       0.658815  0.673101             0.671102  0.651641   \n",
       "8        0.657753       0.664917  0.673070             0.669051  0.672123   \n",
       "9        0.649684       0.652756  0.657816             0.666011  0.641542   \n",
       "10       0.654734       0.661919  0.669072             0.660888  0.658794   \n",
       "11       0.642468       0.640385  0.667000             0.672112  0.658826   \n",
       "12       0.651683       0.643520  0.657764             0.671050  0.666958   \n",
       "13       0.656827       0.649642  0.669104             0.674195  0.653745   \n",
       "14       0.645624       0.649705  0.663970             0.660888  0.638428   \n",
       "15       0.651736       0.661929  0.664948             0.661908  0.657837   \n",
       "16       0.658868       0.647633  0.658900             0.672165  0.659899   \n",
       "17       0.646518       0.662866  0.675131             0.664938  0.659804   \n",
       "18       0.663886       0.665948  0.675131             0.675110  0.656733   \n",
       "19       0.654650       0.651610  0.666926             0.663865  0.652640   \n",
       "20       0.644456       0.656722  0.670987             0.663823  0.659762   \n",
       "21       0.654818       0.652777  0.662981             0.659952  0.654850   \n",
       "22       0.665927       0.660804  0.667957             0.674111  0.662855   \n",
       "23       0.655712       0.652661  0.663939             0.669051  0.656775   \n",
       "24       0.652714       0.652704  0.659825             0.665001  0.663939   \n",
       "25       0.659878       0.652756  0.666021             0.674195  0.660919   \n",
       "26       0.648664       0.659878  0.662971             0.668073  0.652756   \n",
       "27       0.659836       0.661898  0.669020             0.669009  0.660867   \n",
       "28       0.645582       0.654776  0.660877             0.666021  0.644551   \n",
       "29       0.648548       0.653671  0.665916             0.665895  0.652630   \n",
       "\n",
       "    Neural Network  \n",
       "0         0.663928  \n",
       "1         0.672144  \n",
       "2         0.664885  \n",
       "3         0.666895  \n",
       "4         0.666011  \n",
       "5         0.674111  \n",
       "6         0.671060  \n",
       "7         0.668010  \n",
       "8         0.669051  \n",
       "9         0.673185  \n",
       "10        0.672133  \n",
       "11        0.671071  \n",
       "12        0.671050  \n",
       "13        0.669093  \n",
       "14        0.657785  \n",
       "15        0.663981  \n",
       "16        0.666979  \n",
       "17        0.674111  \n",
       "18        0.662866  \n",
       "19        0.666937  \n",
       "20        0.666895  \n",
       "21        0.660961  \n",
       "22        0.672060  \n",
       "23        0.668031  \n",
       "24        0.671060  \n",
       "25        0.674206  \n",
       "26        0.674206  \n",
       "27        0.665979  \n",
       "28        0.670093  \n",
       "29        0.656701  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({\"Decision Tree\": dec_tree_results,\n",
    "                        'Random Forest': random_f_results,\n",
    "                        \"KNN\": knn_results,\n",
    "                        \"Logistic Regression\": logistic_results,\n",
    "                        'SVM': svm_results,\n",
    "                        'Neural Network': neural_net_results\n",
    "                        })\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>KNN</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Neural Network</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.651878</td>\n",
       "      <td>0.656034</td>\n",
       "      <td>0.665291</td>\n",
       "      <td>0.667983</td>\n",
       "      <td>0.655592</td>\n",
       "      <td>0.668183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.007031</td>\n",
       "      <td>0.007880</td>\n",
       "      <td>0.005311</td>\n",
       "      <td>0.004849</td>\n",
       "      <td>0.007874</td>\n",
       "      <td>0.004681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.632369</td>\n",
       "      <td>0.640385</td>\n",
       "      <td>0.655817</td>\n",
       "      <td>0.659952</td>\n",
       "      <td>0.638428</td>\n",
       "      <td>0.656701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.646552</td>\n",
       "      <td>0.651873</td>\n",
       "      <td>0.661143</td>\n",
       "      <td>0.664133</td>\n",
       "      <td>0.652633</td>\n",
       "      <td>0.665987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.652635</td>\n",
       "      <td>0.654739</td>\n",
       "      <td>0.665969</td>\n",
       "      <td>0.667999</td>\n",
       "      <td>0.656754</td>\n",
       "      <td>0.668541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.656509</td>\n",
       "      <td>0.661624</td>\n",
       "      <td>0.668767</td>\n",
       "      <td>0.671860</td>\n",
       "      <td>0.660625</td>\n",
       "      <td>0.671813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.665927</td>\n",
       "      <td>0.680297</td>\n",
       "      <td>0.675131</td>\n",
       "      <td>0.677183</td>\n",
       "      <td>0.672123</td>\n",
       "      <td>0.674206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Decision Tree  Random Forest        KNN  Logistic Regression  \\\n",
       "count      30.000000      30.000000  30.000000            30.000000   \n",
       "mean        0.651878       0.656034   0.665291             0.667983   \n",
       "std         0.007031       0.007880   0.005311             0.004849   \n",
       "min         0.632369       0.640385   0.655817             0.659952   \n",
       "25%         0.646552       0.651873   0.661143             0.664133   \n",
       "50%         0.652635       0.654739   0.665969             0.667999   \n",
       "75%         0.656509       0.661624   0.668767             0.671860   \n",
       "max         0.665927       0.680297   0.675131             0.677183   \n",
       "\n",
       "             SVM  Neural Network  \n",
       "count  30.000000       30.000000  \n",
       "mean    0.655592        0.668183  \n",
       "std     0.007874        0.004681  \n",
       "min     0.638428        0.656701  \n",
       "25%     0.652633        0.665987  \n",
       "50%     0.656754        0.668541  \n",
       "75%     0.660625        0.671813  \n",
       "max     0.672123        0.674206  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normality test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import shapiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ShapiroResult(statistic=0.9756958057031239, pvalue=0.7032287341692791),\n",
       " ShapiroResult(statistic=0.953816962803476, pvalue=0.21368865381427982),\n",
       " ShapiroResult(statistic=0.9686306774828015, pvalue=0.5024204472982673),\n",
       " ShapiroResult(statistic=0.9617442286514929, pvalue=0.34299621275020814),\n",
       " ShapiroResult(statistic=0.9643838432106665, pvalue=0.3987946394238008),\n",
       " ShapiroResult(statistic=0.9356476429626401, pvalue=0.06948007508054126))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = 0.05\n",
    "shapiro(dec_tree_results), shapiro(random_f_results), shapiro(knn_results), shapiro(logistic_results), shapiro(svm_results), shapiro(neural_net_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If p-value >= alpha, then we can NOT REJECT the null hypothesis (H0), aka, the sample have a normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anova teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f_oneway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H0 can be REJECTED. Aka, data is different or data mean is different.\n"
     ]
    }
   ],
   "source": [
    "p = f_oneway(dec_tree_results,random_f_results,knn_results,logistic_results,svm_results,neural_net_results)\n",
    "\n",
    "alpha = 0.05\n",
    "if p.pvalue <= alpha:\n",
    "    print('H0 can be REJECTED. Aka, data is different or data mean is different.')\n",
    "else:\n",
    "    print('H0 can be NOT REJECTED. Aka, data is the same or mean of groups are the same.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tukey teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.multicomp import MultiComparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Multiple Comparison of Means - Tukey HSD, FWER=0.05     \n",
      "============================================================\n",
      "  group1     group2   meandiff p-adj   lower   upper  reject\n",
      "------------------------------------------------------------\n",
      "       knn   logistic   0.0027 0.5839 -0.0021  0.0075  False\n",
      "       knn neural_net   0.0029 0.5044 -0.0019  0.0077  False\n",
      "       knn   random_f  -0.0093    0.0  -0.014 -0.0045   True\n",
      "       knn        svm  -0.0097    0.0 -0.0145 -0.0049   True\n",
      "       knn       tree  -0.0134    0.0 -0.0182 -0.0086   True\n",
      "  logistic neural_net   0.0002    1.0 -0.0046   0.005  False\n",
      "  logistic   random_f  -0.0119    0.0 -0.0167 -0.0072   True\n",
      "  logistic        svm  -0.0124    0.0 -0.0172 -0.0076   True\n",
      "  logistic       tree  -0.0161    0.0 -0.0209 -0.0113   True\n",
      "neural_net   random_f  -0.0121    0.0 -0.0169 -0.0074   True\n",
      "neural_net        svm  -0.0126    0.0 -0.0174 -0.0078   True\n",
      "neural_net       tree  -0.0163    0.0 -0.0211 -0.0115   True\n",
      "  random_f        svm  -0.0004 0.9998 -0.0052  0.0043  False\n",
      "  random_f       tree  -0.0042 0.1275 -0.0089  0.0006  False\n",
      "       svm       tree  -0.0037 0.2248 -0.0085  0.0011  False\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "algorithm_results = {'accuracy': np.concatenate([dec_tree_results,random_f_results,knn_results,logistic_results,svm_results,neural_net_results]),\n",
    "                     'algorithm': \n",
    "                     ['tree','tree','tree','tree','tree','tree','tree','tree','tree','tree','tree','tree','tree','tree','tree','tree','tree','tree','tree','tree','tree','tree','tree','tree','tree','tree','tree','tree','tree','tree',\n",
    "                      'random_f','random_f','random_f','random_f','random_f','random_f','random_f','random_f','random_f','random_f','random_f','random_f','random_f','random_f','random_f','random_f','random_f','random_f','random_f','random_f','random_f','random_f','random_f','random_f','random_f','random_f','random_f','random_f','random_f','random_f',\n",
    "                      'knn','knn','knn','knn','knn','knn','knn','knn','knn','knn','knn','knn','knn','knn','knn','knn','knn','knn','knn','knn','knn','knn','knn','knn','knn','knn','knn','knn','knn','knn',\n",
    "                      'logistic','logistic','logistic','logistic','logistic','logistic','logistic','logistic','logistic','logistic','logistic','logistic','logistic','logistic','logistic','logistic','logistic','logistic','logistic','logistic','logistic','logistic','logistic','logistic','logistic','logistic','logistic','logistic','logistic','logistic',\n",
    "                      'svm','svm','svm','svm','svm','svm','svm','svm','svm','svm','svm','svm','svm','svm','svm','svm','svm','svm','svm','svm','svm','svm','svm','svm','svm','svm','svm','svm','svm','svm',\n",
    "                      'neural_net','neural_net','neural_net','neural_net','neural_net','neural_net','neural_net','neural_net','neural_net','neural_net','neural_net','neural_net','neural_net','neural_net','neural_net','neural_net','neural_net','neural_net','neural_net','neural_net','neural_net','neural_net','neural_net','neural_net','neural_net','neural_net','neural_net','neural_net','neural_net','neural_net']}\n",
    "\n",
    "algorithm_results_df = pd.DataFrame(algorithm_results)\n",
    "comparison = MultiComparison(algorithm_results_df['accuracy'],algorithm_results_df['algorithm'])\n",
    "\n",
    "tukey_test = comparison.tukeyhsd()\n",
    "print(tukey_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tukey_test.plot_simultaneous();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
